{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# AIT Development notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## notebook of structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "| #  | Name                                               | cells | for_dev | edit               | description                                                                |\n",
    "|----|----------------------------------------------------|-------|---------|--------------------|----------------------------------------------------------------------------|\n",
    "| 1  | [Environment detection](##1-Environment-detection) | 1     | No      | uneditable         | detect whether the notebook are invoked for packaging or in production     |\n",
    "| 2  | [Preparing AIT SDK](##2-Preparing-AIT-SDK)         | 1     | Yes     | uneditable         | download and install AIT SDK                                               |\n",
    "| 3  | [Dependency Management](##3-Dependency-Management) | 3     | Yes     | required(cell #2)  | generate requirements.txt for Docker container                             |\n",
    "| 4  | [Importing Libraries](##4-Importing-Libraries)     | 2     | Yes     | required(cell #1)  | import required libraries                                                  |\n",
    "| 5  | [Manifest Generation](##5-Manifest-Generation)     | 1     | Yes     | required           | generate AIT Manifest                                                      |\n",
    "| 6  | [Prepare for the Input](##6-Prepare-for-the-Input) | 1     | Yes     | required           | generate AIT Input JSON (inventory mapper)                                 |\n",
    "| 7  | [Initialization](##7-Initialization)               | 1     | No      | uneditable         | initialization for AIT execution                                           |\n",
    "| 8  | [Function definitions](##8-Function-definitions)   | N     | No      | required           | define functions invoked from Main area.<br> also define output functions. |\n",
    "| 9  | [Main Algorithms](##9-Main-Algorithms)             | 1     | No      | required           | area for main algorithms of an AIT                                         |\n",
    "| 10 | [Entry point](##10-Entry-point)                    | 1     | No      | uneditable         | an entry point where Qunomon invoke this AIT from here                     |\n",
    "| 11 | [License](##11-License)                            | 1     | Yes     | required           | generate license information                                               |\n",
    "| 12 | [Deployment](##12-Deployment)                      | 1     | Yes     | uneditable         | convert this notebook to the python file for packaging purpose             |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## notebook template revision history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "1.0.1 2020/10/21\n",
    "\n",
    "* add revision history\n",
    "* separate `create requirements and pip install` editable and noeditable\n",
    "* separate `import` editable and noeditable\n",
    "\n",
    "1.0.0 2020/10/12\n",
    "\n",
    "* new cerarion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### #1 Environment detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "[uneditable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Determine whether to start AIT or jupyter by startup argument\n",
    "import sys\n",
    "is_ait_launch = (len(sys.argv) == 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### #2 Preparing AIT SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "[uneditable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "if not is_ait_launch:\n",
    "    # get ait-sdk file name\n",
    "    from pathlib import Path\n",
    "    from glob import glob\n",
    "    import re\n",
    "    import os\n",
    "\n",
    "    current_dir = %pwd\n",
    "\n",
    "    ait_sdk_path = \"./ait_sdk-*-py3-none-any.whl\"\n",
    "    ait_sdk_list = glob(ait_sdk_path)\n",
    "    ait_sdk_name = os.path.basename(ait_sdk_list[-1])\n",
    "\n",
    "    # install ait-sdk\n",
    "    !pip install -q --upgrade pip\n",
    "    !pip install -q --no-deps --force-reinstall ./$ait_sdk_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### #3 Dependency Management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### #3-1 [uneditable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "if not is_ait_launch:\n",
    "    from ait_sdk.common.files.ait_requirements_generator import AITRequirementsGenerator\n",
    "    requirements_generator = AITRequirementsGenerator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### #3-2 [required]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_ait_launch:\n",
    "    requirements_generator.add_package('numpy', '2.0.2')\n",
    "    requirements_generator.add_package('matplotlib', '3.10.1')\n",
    "    requirements_generator.add_package('pandas', '2.2.3')\n",
    "    requirements_generator.add_package('scikit-learn', '1.6.1')\n",
    "    requirements_generator.add_package('tensorflow', '2.18.1')\n",
    "    requirements_generator.add_package('scipy', '1.15.2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### #3-3 [uneditable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "if not is_ait_launch:\n",
    "    requirements_generator.add_package(f'./{ait_sdk_name}')\n",
    "    requirements_path = requirements_generator.create_requirements(current_dir)\n",
    "\n",
    "    !pip install -q -r $requirements_path "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### #4 Importing Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### #4-1 [required]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-17 14:03:24.661240: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-17 14:03:24.661768: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-17 14:03:24.663815: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-17 14:03:24.669944: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744866204.680097      28 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744866204.683054      28 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-17 14:03:24.694068: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# import if you need modules cell\n",
    "# from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, Input, Flatten, Dense, Lambda, Reshape, BatchNormalization, MaxPooling2D, Dropout\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "from collections import defaultdict \n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from scipy import stats\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score \n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, matthews_corrcoef\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### #4-2 [uneditable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# must use modules\n",
    "from os import path\n",
    "import shutil  # do not remove\n",
    "from ait_sdk.common.files.ait_input import AITInput  # do not remove\n",
    "from ait_sdk.common.files.ait_output import AITOutput  # do not remove\n",
    "from ait_sdk.common.files.ait_manifest import AITManifest  # do not remove\n",
    "from ait_sdk.develop.ait_path_helper import AITPathHelper  # do not remove\n",
    "from ait_sdk.utils.logging import get_logger, log, get_log_path  # do not remove\n",
    "from ait_sdk.develop.annotation import measures, resources, downloads, ait_main  # do not remove\n",
    "# must use modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### #5 Manifest Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "[required]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_ait_launch:\n",
    "    from ait_sdk.common.files.ait_manifest_generator import AITManifestGenerator\n",
    "    manifest_generator = AITManifestGenerator(current_dir)\n",
    "    manifest_generator.set_ait_name('eval_noise_score_aquavs')\n",
    "    manifest_generator.set_ait_description('モデルの安定性を評価するために、ノイズを付けたラベルで検証します。\\\n",
    "SVAEの潜在表現を使用し、入力データセット内の各サンプルの異常を測定する「ノイズスコア」を計測します。\\\n",
    "詳細については、元の論文「Pulastya, et al. Assessing the quality of the datasets by identifying mislabeled samples」\\\n",
    "(URL: https://dl.acm.org/doi/abs/10.1145/3487351.3488361)')\n",
    "\n",
    "    manifest_generator.set_ait_source_repository('https://github.com/aistairc/Qunomon_AIT_eval_noise_score_aquavs')\n",
    "    manifest_generator.add_ait_licenses('Apache License Version 2.0')\n",
    "    manifest_generator.set_ait_version('1.5')\n",
    "    manifest_generator.add_ait_keywords('Evaluation')\n",
    "    manifest_generator.set_ait_quality('https://ait-hub.pj.aist.go.jp/ait-hub/api/0.0.1/qualityDimensions/機械学習品質マネジメントガイドライン第三版/C-2機械学習モデルの安定性')\n",
    "    \n",
    "    # inventories\n",
    "    inventory_requirement_image_dataset = manifest_generator.format_ait_inventory_requirement(format_=['npz'])\n",
    "    manifest_generator.add_ait_inventories(name='image_dataset', \n",
    "                                           type_='dataset', \n",
    "                                           description='画像データセット ※以下の4つのみ利用可能：mnist data, fashion mnist data, cifar10 data, cifar100 data', \n",
    "                                           requirement=inventory_requirement_image_dataset)\n",
    "\n",
    "    # input parameters, Hyperparameters\n",
    "    manifest_generator.add_ait_parameters(name='MAD_Outlier_constant', \n",
    "                                          type_='float', \n",
    "                                          default_val='1.5', \n",
    "                                          description='潜在空間における外れ値検出を指定するハイパーパラメーター')\n",
    "    manifest_generator.add_ait_parameters(name='MISLABEL_THRESHOLD', \n",
    "                                          type_='float', \n",
    "                                          default_val='0.5', \n",
    "                                          description='外れ値次元の割合に基づく誤ラベルを指定するハイパーパラメーター')\n",
    "    manifest_generator.add_ait_parameters(name='latent_dim', \n",
    "                                          type_='int', \n",
    "                                          default_val='100', \n",
    "                                          description='潜在空間の次元を指定するハイパーパラメーター')\n",
    "    manifest_generator.add_ait_parameters(name='batch_size', \n",
    "                                          type_='int', \n",
    "                                          default_val='32', \n",
    "                                          description='VAEのオプティマイザのバッチサイズを指定するハイパーパラメーター')\n",
    "    \n",
    "    # input parameters\n",
    "    manifest_generator.add_ait_parameters(name='datasetName', \n",
    "                                          type_='str', \n",
    "                                          default_val='mnist', \n",
    "                                          description='データセットを指定するパラメーター ※指定値について以下の4つのみ利用可能：mnist, fashion_mnist, cifar10, cifar100')\n",
    "    manifest_generator.add_ait_parameters(name='noise_perc', \n",
    "                                          type_='float', \n",
    "                                          default_val='20', \n",
    "                                          description='ノイズ付きラベルの割合を指定するパラメーター')\n",
    "    manifest_generator.add_ait_parameters(name='noise_systematic', \n",
    "                                          type_='str', \n",
    "                                          default_val='Sys', \n",
    "                                          description='ラベル値に基づいてノイズを加えるタイプを指定するパラメーター ※指定値についてSysまたはUni')\n",
    "    manifest_generator.add_ait_parameters(name='model_name', \n",
    "                                          type_='str', \n",
    "                                          default_val='', \n",
    "                                          description='VAEモデル名称を指定するパラメーター')\n",
    "    \n",
    "    # measures: evaluation metrics\n",
    "    manifest_generator.add_ait_measures(name='evaluation_result_accuracy', \n",
    "                                        type_='float', \n",
    "                                        structure='single', \n",
    "                                        min='0', \n",
    "                                        max='1', \n",
    "                                        description='正確度（精度）')\n",
    "    manifest_generator.add_ait_measures(name='evaluation_result_precision', \n",
    "                                        type_='float', \n",
    "                                        structure='single', \n",
    "                                        min='0', \n",
    "                                        max='1', \n",
    "                                        description='適合率')\n",
    "    manifest_generator.add_ait_measures(name='evaluation_result_recall', \n",
    "                                        type_='float', \n",
    "                                        structure='single', \n",
    "                                        min='0', \n",
    "                                        max='1', \n",
    "                                        description='再現率')\n",
    "    manifest_generator.add_ait_measures(name='evaluation_result_f1', \n",
    "                                        type_='float', \n",
    "                                        structure='single', \n",
    "                                        min='0', \n",
    "                                        max='1', \n",
    "                                        description='F1スコア')\n",
    "    manifest_generator.add_ait_measures(name='evaluation_result_roc_auc', \n",
    "                                        type_='float', \n",
    "                                        structure='single', \n",
    "                                        min='0', \n",
    "                                        max='1', \n",
    "                                        description='ROC曲線下面積（AUC）')\n",
    "    manifest_generator.add_ait_measures(name='evaluation_result_mcc', \n",
    "                                        type_='float', \n",
    "                                        structure='single', \n",
    "                                        min='0', \n",
    "                                        max='1', \n",
    "                                        description='マシューズ相関係数')\n",
    "\n",
    "    # download: VAE model\n",
    "    manifest_generator.add_ait_downloads(name='vae', \n",
    "                                         description='トレーニング済みVAEモデル')\n",
    "    manifest_generator.add_ait_downloads(name='Log', \n",
    "                                         description='AITの実行ログ')\n",
    "    manifest_path = manifest_generator.write()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### #6 Prepare for the Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "[required]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_ait_launch:\n",
    "    from ait_sdk.common.files.ait_input_generator import AITInputGenerator\n",
    "    input_generator = AITInputGenerator(manifest_path)\n",
    "    input_generator.add_ait_inventories(name='image_dataset',\n",
    "                                        value='mnist_data/mnist_train_data.npz')\n",
    "\n",
    "    input_generator.set_ait_params(name='MAD_Outlier_constant', value=1.5)\n",
    "    input_generator.set_ait_params(name='MISLABEL_THRESHOLD', value= 0.5)\n",
    "    input_generator.set_ait_params(name='latent_dim', value=100)\n",
    "    input_generator.set_ait_params(name='batch_size', value=32)\n",
    "    input_generator.set_ait_params(name='datasetName', value='mnist')\n",
    "    input_generator.set_ait_params(name='noise_perc', value=10)\n",
    "    input_generator.set_ait_params(name='noise_systematic', value='Sys')\n",
    "    input_generator.set_ait_params(name='model_name', value='vae_mnist_Sys_10.keras')\n",
    "\n",
    "    input_generator.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### #7 Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "[uneditable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "logger = get_logger()\n",
    "\n",
    "ait_manifest = AITManifest()\n",
    "ait_input = AITInput(ait_manifest)\n",
    "ait_output = AITOutput(ait_manifest)\n",
    "\n",
    "if is_ait_launch:\n",
    "    # launch from AIT\n",
    "    current_dir = path.dirname(path.abspath(__file__))\n",
    "    path_helper = AITPathHelper(argv=sys.argv, ait_input=ait_input, ait_manifest=ait_manifest, entry_point_dir=current_dir)\n",
    "else:\n",
    "    # launch from jupyter notebook\n",
    "    # ait.input.json make in input_dir\n",
    "    input_dir = '/usr/local/qai/mnt/ip/job_args/1/1'\n",
    "    current_dir = %pwd\n",
    "    path_helper = AITPathHelper(argv=['', input_dir], ait_input=ait_input, ait_manifest=ait_manifest, entry_point_dir=current_dir)\n",
    "\n",
    "ait_input.read_json(path_helper.get_input_file_path())\n",
    "ait_manifest.read_json(path_helper.get_manifest_file_path())\n",
    "\n",
    "### do not edit cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### #8 Function definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "[required]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### helper function\n",
    "def specify_dimensions(datasetName):\n",
    "    if datasetName == 'mnist' or datasetName == 'fashion_mnist':\n",
    "        # constants to specify model details\n",
    "        img_dimensions = (28, 28, 1)\n",
    "        num_classes = 10\n",
    "        num_channels = 1\n",
    "    elif datasetName == 'cifar10':\n",
    "        # constants to specify model details\n",
    "        img_dimensions = (32, 32, 3)\n",
    "        num_classes = 10\n",
    "        num_channels = 3\n",
    "    elif datasetName == 'cifar100':\n",
    "        # constants to specify model details\n",
    "        img_dimensions = (32, 32, 3)\n",
    "        num_classes = 100\n",
    "        num_channels = 3\n",
    "    else:\n",
    "        raise ValueError\n",
    "    return img_dimensions, num_classes, num_channels\n",
    "\n",
    "def prepare_data(datasetName, train_data, train_labels, noisePerc, noiseType):\n",
    "    img_dimensions, num_classes, num_channels = specify_dimensions(datasetName)\n",
    "    \n",
    "    #adds noise to y-labels using uniform noise model - i.e. mislabeled samples are given labels uniformly at random.\n",
    "    def add_noise_UniformNoiseModel(input_y, perc, allClasses):\n",
    "        final_idx = defaultdict(list)\n",
    "        noisy_y = [-1 for i in range(input_y.shape[0])]\n",
    "\n",
    "        for i in range(input_y.shape[0]): \n",
    "            final_idx[input_y[i]].append(i)\n",
    "\n",
    "        for lbl in final_idx.keys():\n",
    "            remC = (perc/100.0)*len(final_idx[lbl])\n",
    "            #print(\"Label: \", lbl, \"; # of datapoints flipped: \", int(remC))\n",
    "            for i in range(int(remC)):\n",
    "                idx = random.randint(0, len(final_idx[lbl]) - 1)\n",
    "                newLabel = random.choice(allClasses)\n",
    "                while (newLabel == lbl):\n",
    "                    newLabel = random.choice(allClasses)\n",
    "                noisy_y[final_idx[lbl][idx]] = newLabel  # update the label for datapoint from `label` to `newLabel` \n",
    "                del final_idx[lbl][idx]\n",
    "\n",
    "        for lbl in final_idx.keys():\n",
    "            for i in final_idx[lbl]:\n",
    "                noisy_y[i] = lbl\n",
    "\n",
    "        return np.array(noisy_y)\n",
    "\n",
    "    #adds noise to y-labels using systematic noise model - i.e. mislabeled samples are given labels systematic at random.\n",
    "    def add_noise_SystematicNoiseModel(input_y, perc, allClasses):\n",
    "        final_idx = defaultdict(list)\n",
    "        noisy_y = [-1 for i in range(input_y.shape[0])]\n",
    "\n",
    "        for i in range(input_y.shape[0]): \n",
    "            final_idx[input_y[i]].append(i)\n",
    "\n",
    "        for lbl in final_idx.keys():\n",
    "            remC = (perc/100.0)*len(final_idx[lbl])\n",
    "            #print(\"Label: \", lbl, \"; # of datapoints flipped: \", int(remC))\n",
    "            for i in range(int(remC)):\n",
    "                idx = random.randint(0, len(final_idx[lbl]) - 1)\n",
    "                newLabel = (lbl + 1)%(len(allClasses))\n",
    "                noisy_y[final_idx[lbl][idx]] = newLabel  # update the label for datapoint from `label` to `newLabel` \n",
    "                del final_idx[lbl][idx]\n",
    "\n",
    "        for lbl in final_idx.keys():\n",
    "            for i in final_idx[lbl]:\n",
    "                noisy_y[i] = lbl\n",
    "\n",
    "        return np.array(noisy_y)\n",
    "\n",
    "    # min-max normalization\n",
    "    def min_max_normalize(lis):\n",
    "        minL = float(min(lis))\n",
    "        maxL = float(max(lis))\n",
    "        minMaxLis = [float((float(x) - minL)/ (maxL - minL)) for x in lis]\n",
    "        return minMaxLis  \n",
    "    \n",
    "    #reshaping\n",
    "    train_data = train_data.reshape((train_data.shape[0], img_dimensions[0], img_dimensions[1], img_dimensions[2]))\n",
    "    train_labels = train_labels.reshape(train_labels.shape[0])\n",
    "\n",
    "    # convert from integers to floats\n",
    "    train_data = train_data.astype('float32')\n",
    "\n",
    "    # normalize to range 0-1\n",
    "    train_data = train_data / 255.0\n",
    "\n",
    "    if(noiseType == \"Sys\"):\n",
    "        noisy_labels = add_noise_SystematicNoiseModel(train_labels, noisePerc, [cl for cl in range(10)])\n",
    "    elif(noiseType == \"Uni\"):\n",
    "        noisy_labels = add_noise_UniformNoiseModel(train_labels, noisePerc, [cl for cl in range(10)])\n",
    "\n",
    "    grn_truth = np.array(noisy_labels == train_labels, dtype=int)\n",
    "\n",
    "    print(\"Number of mislabeled: \", len(grn_truth) - sum(grn_truth), \"out of\", len(grn_truth))\n",
    "\n",
    "    y_enc_noisy_labels = tf.keras.utils.to_categorical(noisy_labels) #encode noisy labels\n",
    "\n",
    "    return train_data, noisy_labels, grn_truth, y_enc_noisy_labels\n",
    "\n",
    "# grouping datapoints by respective classes\n",
    "def group_data_by_class(input_x, input_y):\n",
    "    final_out = defaultdict(list) \n",
    "    final_idx = defaultdict(list)\n",
    "    for i in range(input_x.shape[0]): \n",
    "        final_out[input_y[i]].append(input_x[i])\n",
    "        final_idx[input_y[i]].append(i)\n",
    "    return final_out, final_idx\n",
    "\n",
    "# Ref - https://core.ac.uk/download/pdf/206095228.pdf\n",
    "def outlier_detection_med_mad(input_data, k1):\n",
    "    column_med = np.median(input_data, axis = 0)\n",
    "    column_mad = stats.median_abs_deviation(input_data,axis = 0)\n",
    "\n",
    "    #computing threshold for each feature\n",
    "    threshold_lower = column_med - (k1*column_mad)\n",
    "    threshold_upper = column_med + (k1*column_mad)\n",
    "    outliers = []\n",
    "    num_outlier_feature_list = []\n",
    "    outlier_level = defaultdict(list)\n",
    "    for i in range(input_data.shape[0]):\n",
    "        num_outlier_feature = 0\n",
    "        x = input_data[i]\n",
    "        for id in range(x.shape[0]):\n",
    "            if not (threshold_lower[id] <= x[id] and x[id] <= threshold_upper[id]):\n",
    "                num_outlier_feature += 1\n",
    "        outlier_level[num_outlier_feature].append(i)\n",
    "    return outlier_level\n",
    "\n",
    "# computes noise level of each datapoint \n",
    "def get_train_lvl(encoder, input_x, input_y, MAD_Outlier_constant):\n",
    "    grouped_train, grouped_idx = group_data_by_class(input_x, input_y.reshape(input_y.shape[0]))\n",
    "    cntr = 0\n",
    "    train_lvl = [-1 for i in range(input_x.shape[0])]\n",
    "    for digit in range(0,10):\n",
    "        z_values = encoder.predict(np.array(grouped_train[digit]))[2]\n",
    "        class_outliers = outlier_detection_med_mad(z_values, MAD_Outlier_constant)\n",
    "        for i in class_outliers.keys():\n",
    "            for j in class_outliers[i]:\n",
    "                # i is the outlier level\n",
    "                # grouped_idx[digit][j] is the index\n",
    "                train_lvl[grouped_idx[digit][j]] = i\n",
    "    return np.array(train_lvl)\n",
    "\n",
    "### main functions\n",
    "@log(logger)\n",
    "@downloads(ait_output, path_helper, 'vae', 'vae_model_learned.keras')\n",
    "def optimize_AQUAVS(datasetName, train_data, y_enc_noisy_labels, latent_dim, batch_size, model_name, file_path = None):\n",
    "    img_dimensions, num_classes, num_channels = specify_dimensions(datasetName)\n",
    "    \n",
    "    # VAE \n",
    "    def vae_loss(data, reconstruction):\n",
    "        z_mean, z_log_var, z = encoder(data)\n",
    "        reconstruction_loss = keras.losses.binary_crossentropy(data, reconstruction)\n",
    "        reconstruction_loss = tf.reduce_mean(reconstruction_loss, axis=[1,2])\n",
    "        kl_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n",
    "        kl_loss = tf.reduce_mean(kl_loss, axis=1)\n",
    "        kl_loss *= -0.5\n",
    "        total_loss = tf.reduce_mean(reconstruction_loss + kl_loss)/100\n",
    "        return total_loss\n",
    "\n",
    "    def sampling(args):\n",
    "        z_mean, z_var = args\n",
    "        epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0,)  ## latent_dim = K.shape(z_mean)[1] \n",
    "        return z_mean + K.exp(z_var / 2) * epsilon\n",
    "\n",
    "    ## ENCODER\n",
    "    inputNode = Input(shape=img_dimensions, name=\"EncoderInput\")\n",
    "    enc_inter = Conv2D(filters=32, kernel_size=4, strides=2, padding='same', kernel_initializer='he_uniform')(inputNode)\n",
    "    enc_inter = Conv2D(filters=64, kernel_size=4, strides=2, padding='same', kernel_initializer='he_uniform', activation='relu')(enc_inter)\n",
    "    enc_inter = Conv2D(filters=128, kernel_size=4, strides=1, padding='same', kernel_initializer='he_uniform', activation=tf.nn.relu)(enc_inter)\n",
    "\n",
    "    conv_shape = K.int_shape(enc_inter) \n",
    "\n",
    "    enc_inter = Flatten()(enc_inter)\n",
    "    z_mean = Dense(latent_dim, name=\"Mean\")(enc_inter)\n",
    "    z_var = Dense(latent_dim, name=\"Variance\")(enc_inter)\n",
    "    z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_var])\n",
    "    encoder = Model(inputNode, [z_mean, z_var, z], name=\"Encoder\")\n",
    "\n",
    "    ## CLASSIFIER\n",
    "    clf_latent_inputs = Input(shape=(latent_dim,), name='ClassifierInput')\n",
    "    clf_outputs = Dense(num_classes, activation='softmax', name='ClassifierOutput')(clf_latent_inputs)\n",
    "    clf_supervised = Model(clf_latent_inputs, clf_outputs, name='Classifier')\n",
    "\n",
    "    ## DECODER\n",
    "    inputNode2 = Input(shape=(latent_dim,), name=\"DecoderInput\")\n",
    "    dec_inter = Dense(conv_shape[1]*conv_shape[2]*conv_shape[3])(inputNode2)\n",
    "    dec_inter = Reshape((conv_shape[1], conv_shape[2], conv_shape[3]))(dec_inter)\n",
    "    dec_inter = Conv2DTranspose(filters=128, kernel_size=4, strides=1, padding='same', kernel_initializer='he_uniform', activation='relu')(dec_inter)\n",
    "    dec_inter = Conv2DTranspose(filters=64, kernel_size=4, strides=2, padding='same', kernel_initializer='he_uniform', activation='relu')(dec_inter)\n",
    "    dec_inter = Conv2DTranspose(filters=32, kernel_size=4, strides=2, padding='same', kernel_initializer='he_uniform', activation='relu')(dec_inter)\n",
    "    decoder_node = Conv2DTranspose(num_channels, kernel_size=4, strides=1, padding='same')(dec_inter)\n",
    "    decoder = Model(inputNode2, decoder_node, name='Decoder')\n",
    "\n",
    "    output_combined = [decoder(encoder(inputNode)[2]), clf_supervised(encoder(inputNode)[2])]\n",
    "    vae = Model(inputNode, output_combined, name='S-VAE')\n",
    "\n",
    "    vae.compile(optimizer='adam', loss=[vae_loss, 'categorical_crossentropy'])\n",
    "\n",
    "    # callback definitions\n",
    "    def scheduler(epoch):\n",
    "        return 0.001/(epoch+1)\n",
    "\n",
    "    earlyStopCallback = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        min_delta=0,\n",
    "        patience=0,\n",
    "        verbose=0,\n",
    "        mode=\"auto\",\n",
    "        baseline=None,\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "\n",
    "    lrScheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "    splitID = int(0.8*len(train_data))\n",
    "\n",
    "    #Note - VAE trains on noisy data\n",
    "    vae.fit(train_data[:splitID], [train_data[:splitID], y_enc_noisy_labels[:splitID]], \n",
    "            shuffle=True, epochs=10, batch_size=batch_size, \n",
    "            validation_data=(train_data[splitID:], [train_data[splitID:], y_enc_noisy_labels[splitID:]]), \n",
    "            callbacks=[lrScheduler, earlyStopCallback],\n",
    "            verbose=1)\n",
    "\n",
    "    model_name = file_path\n",
    "    if model_name is not None:\n",
    "        vae.save(model_name)\n",
    "    return vae\n",
    "\n",
    "\n",
    "@log(logger)\n",
    "@measures(ait_output, 'evaluation_result_accuracy')\n",
    "def evaluate_accuracy_AQUAVS(encoder, train_data, noisy_labels, grn_truth, MAD_Outlier_constant, MISLABEL_THRESHOLD, latent_dim):\n",
    "    \n",
    "    noisy_lvl = get_train_lvl(encoder, train_data, noisy_labels, MAD_Outlier_constant)\n",
    "\n",
    "    # identify mislabel\n",
    "    true_mislabels = grn_truth\n",
    "    estimated_mislabels = np.where(noisy_lvl / latent_dim <= MISLABEL_THRESHOLD, 1, 0)\n",
    "\n",
    "    # evaluate the differnce between true_mislabels vs estimated_mislabels\n",
    "    return accuracy_score(true_mislabels, estimated_mislabels)\n",
    "\n",
    "@log(logger)\n",
    "@measures(ait_output, 'evaluation_result_precision')\n",
    "def evaluate_precision_AQUAVS(encoder, train_data, noisy_labels, grn_truth, MAD_Outlier_constant, MISLABEL_THRESHOLD, latent_dim):\n",
    "    \n",
    "    noisy_lvl = get_train_lvl(encoder, train_data, noisy_labels, MAD_Outlier_constant)\n",
    "\n",
    "    # identify mislabel\n",
    "    true_mislabels = grn_truth\n",
    "    estimated_mislabels = np.where(noisy_lvl / latent_dim <= MISLABEL_THRESHOLD, 1, 0)\n",
    "\n",
    "    # evaluate the differnce between true_mislabels vs estimated_mislabels\n",
    "    return precision_score(true_mislabels, estimated_mislabels)\n",
    "\n",
    "@log(logger)\n",
    "@measures(ait_output, 'evaluation_result_recall')\n",
    "def evaluate_recall_AQUAVS(encoder, train_data, noisy_labels, grn_truth, MAD_Outlier_constant, MISLABEL_THRESHOLD, latent_dim):\n",
    "    \n",
    "    noisy_lvl = get_train_lvl(encoder, train_data, noisy_labels, MAD_Outlier_constant)\n",
    "\n",
    "    # identify mislabel\n",
    "    true_mislabels = grn_truth\n",
    "    estimated_mislabels = np.where(noisy_lvl / latent_dim <= MISLABEL_THRESHOLD, 1, 0)\n",
    "\n",
    "    # evaluate the differnce between true_mislabels vs estimated_mislabels\n",
    "    return recall_score(true_mislabels, estimated_mislabels)\n",
    "\n",
    "@log(logger)\n",
    "@measures(ait_output, 'evaluation_result_f1')\n",
    "def evaluate_f1_AQUAVS(encoder, train_data, noisy_labels, grn_truth, MAD_Outlier_constant, MISLABEL_THRESHOLD, latent_dim):\n",
    "    \n",
    "    noisy_lvl = get_train_lvl(encoder, train_data, noisy_labels, MAD_Outlier_constant)\n",
    "\n",
    "    # identify mislabel\n",
    "    true_mislabels = grn_truth\n",
    "    estimated_mislabels = np.where(noisy_lvl / latent_dim <= MISLABEL_THRESHOLD, 1, 0)\n",
    "\n",
    "    # evaluate the differnce between true_mislabels vs estimated_mislabels\n",
    "    return f1_score(true_mislabels, estimated_mislabels)\n",
    "\n",
    "@log(logger)\n",
    "@measures(ait_output, 'evaluation_result_roc_auc')\n",
    "def evaluate_roc_auc_AQUAVS(encoder, train_data, noisy_labels, grn_truth, MAD_Outlier_constant, MISLABEL_THRESHOLD, latent_dim):\n",
    "    \n",
    "    noisy_lvl = get_train_lvl(encoder, train_data, noisy_labels, MAD_Outlier_constant)\n",
    "\n",
    "    # identify mislabel\n",
    "    true_mislabels = grn_truth\n",
    "    estimated_mislabels = np.where(noisy_lvl / latent_dim <= MISLABEL_THRESHOLD, 1, 0)\n",
    "\n",
    "    # evaluate the differnce between true_mislabels vs estimated_mislabels\n",
    "    return roc_auc_score(true_mislabels, estimated_mislabels)\n",
    "\n",
    "@log(logger)\n",
    "@measures(ait_output, 'evaluation_result_mcc')\n",
    "def evaluate_mcc_AQUAVS(encoder, train_data, noisy_labels, grn_truth, MAD_Outlier_constant, MISLABEL_THRESHOLD, latent_dim):\n",
    "    \n",
    "    noisy_lvl = get_train_lvl(encoder, train_data, noisy_labels, MAD_Outlier_constant)\n",
    "\n",
    "    # identify mislabel\n",
    "    true_mislabels = grn_truth\n",
    "    estimated_mislabels = np.where(noisy_lvl / latent_dim <= MISLABEL_THRESHOLD, 1, 0)\n",
    "\n",
    "    # evaluate the differnce between true_mislabels vs estimated_mislabels\n",
    "    return matthews_corrcoef(true_mislabels, estimated_mislabels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@log(logger)\n",
    "@downloads(ait_output, path_helper, 'Log', 'ait.log')\n",
    "def move_log(file_path: str=None) -> str:\n",
    "    shutil.move(get_log_path(), file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### #9 Main Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "[required]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@log(logger)\n",
    "@ait_main(ait_output, path_helper)\n",
    "def main() -> None:\n",
    "    # inventory\n",
    "    input_data = np.load(ait_input.get_inventory_path('image_dataset'))\n",
    "    \n",
    "    # parameters\n",
    "    MAD_Outlier_constant = ait_input.get_method_param_value('MAD_Outlier_constant')\n",
    "    MISLABEL_THRESHOLD = ait_input.get_method_param_value('MISLABEL_THRESHOLD')\n",
    "    latent_dim = ait_input.get_method_param_value('latent_dim')\n",
    "    batch_size = ait_input.get_method_param_value('batch_size')\n",
    "    datasetName = ait_input.get_method_param_value('datasetName')\n",
    "    noise_perc = ait_input.get_method_param_value('noise_perc')\n",
    "    noise_systematic = ait_input.get_method_param_value('noise_systematic')\n",
    "    model_name = ait_input.get_method_param_value('model_name')\n",
    "    \n",
    "    train_data, noisy_labels, grn_truth, y_enc_noisy_labels = prepare_data(datasetName, input_data['X'], input_data['y'], noise_perc, noise_systematic)\n",
    "    \n",
    "    vae = optimize_AQUAVS(datasetName, train_data, y_enc_noisy_labels, latent_dim, batch_size, model_name)\n",
    "    encoder = vae.get_layer('Encoder')\n",
    "    \n",
    "    evaluation_result = evaluate_accuracy_AQUAVS(encoder, train_data, noisy_labels, grn_truth, MAD_Outlier_constant, MISLABEL_THRESHOLD, latent_dim)\n",
    "    evaluation_result = evaluate_precision_AQUAVS(encoder, train_data, noisy_labels, grn_truth, MAD_Outlier_constant, MISLABEL_THRESHOLD, latent_dim)\n",
    "    evaluation_result = evaluate_recall_AQUAVS(encoder, train_data, noisy_labels, grn_truth, MAD_Outlier_constant, MISLABEL_THRESHOLD, latent_dim)\n",
    "    evaluation_result = evaluate_f1_AQUAVS(encoder, train_data, noisy_labels, grn_truth, MAD_Outlier_constant, MISLABEL_THRESHOLD, latent_dim)\n",
    "    evaluation_result = evaluate_roc_auc_AQUAVS(encoder, train_data, noisy_labels, grn_truth, MAD_Outlier_constant, MISLABEL_THRESHOLD, latent_dim)\n",
    "    evaluation_result = evaluate_mcc_AQUAVS(encoder, train_data, noisy_labels, grn_truth, MAD_Outlier_constant, MISLABEL_THRESHOLD, latent_dim)\n",
    "    \n",
    "    move_log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### #10 Entry point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "[uneditable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled:  5996 out of 60000\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-17 14:03:27.623772: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 25ms/step - Classifier_loss: 0.7732 - Decoder_loss: 0.0135 - loss: 0.7868 - val_Classifier_loss: 0.4735 - val_Decoder_loss: 0.0144 - val_loss: 0.4879 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 26ms/step - Classifier_loss: 0.4057 - Decoder_loss: 0.0159 - loss: 0.4216 - val_Classifier_loss: 0.4270 - val_Decoder_loss: 0.0147 - val_loss: 0.4417 - learning_rate: 5.0000e-04\n",
      "Epoch 3/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 26ms/step - Classifier_loss: 0.3411 - Decoder_loss: 0.0165 - loss: 0.3575 - val_Classifier_loss: 0.4333 - val_Decoder_loss: 0.0163 - val_loss: 0.4496 - learning_rate: 3.3333e-04\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### #11 License"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "[required]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ait_owner='AIST'\n",
    "ait_creation_year='2024'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### #12 Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "[uneditable] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "if not is_ait_launch:\n",
    "    from ait_sdk.deploy import prepare_deploy\n",
    "    from ait_sdk.license.license_generator import LicenseGenerator\n",
    "    \n",
    "    current_dir = %pwd\n",
    "    prepare_deploy(ait_sdk_name, current_dir, requirements_path)\n",
    "    \n",
    "    # output License.txt\n",
    "    license_generator = LicenseGenerator()\n",
    "    license_generator.write('../top_dir/LICENSE.txt', ait_creation_year, ait_owner)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "cc00c6a56d87bd8bd7773e730c60ddfdb8804da6b7537df09499efbcf81630f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
